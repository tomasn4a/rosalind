{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting DNA Nucleotides\n",
    "-------------\n",
    "\n",
    "## Problem\n",
    "\n",
    "A string is simply an ordered collection of symbols selected from some alphabet and formed into a word; the length of a string is the number of symbols that it contains.\n",
    "\n",
    "An example of a length 21 DNA string (whose alphabet contains the symbols 'A', 'C', 'G', and 'T') is \"ATGCTTCAGAAAGGTCTTACG.\"\n",
    "\n",
    "**Given**: A DNA string ss of length at most 1000 nt.\n",
    "\n",
    "Return: Four integers (separated by spaces) counting the respective number of times that the symbols 'A', 'C', 'G', and 'T' occur in ss.\n",
    "\n",
    "**Sample Dataset**:\n",
    "\n",
    "    AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTGTCTGATAGCAGC\n",
    "\n",
    "**Sample Output**:\n",
    "\n",
    "    20 12 17 21\n",
    "    \n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "This seemingly simple problem actually provides some good insights on different data structures, performance differences based on built-in functions vs. loops, and big Oh notation. Let's start with the brute force approach: using the built-in 'count' function for each of the nucleotides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 12 17 21\n"
     ]
    }
   ],
   "source": [
    "# We will test on the sample data first\n",
    "sample = \"AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTGTCTGATAGCAGC\"\n",
    "\n",
    "print(sample.count(\"A\"), sample.count(\"C\"), sample.count(\"G\"), sample.count(\"T\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample solution has a very specific format so calling 'count' four times is the quickest. However if instead of just counting the different nucleotides we were counting letter and digit frequency in a regular text it will be very tedious to make 30+ calls. If we don't care too much about formatting we can then use a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 20), ('C', 12), ('G', 17), ('T', 21)]\n"
     ]
    }
   ],
   "source": [
    "# Create a string of all possible values\n",
    "values = \"ACGT\"\n",
    "counts = []\n",
    "# Loop through and count\n",
    "for nuc in values:\n",
    "    counts.append((nuc, sample.count(nuc)))\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How efficient is this brute force approach? In therms of space complexity, we don't need to make any copies or the original array, so it is _O_(1). In terms of time complexity, each time we count a specific letter we loop through the original string once, so in this case we will loop 4 times through the data. It is still an _O_(n) approach but in this case it is good to remember the constant. We will come back to it later when we actually time the performance.\n",
    "\n",
    "Another approach that is perhaps more elegant is using a dictionary. A dictionary is a table that maps keys to values. In this case the keys of the dictionary are the different nucleotides and their values the number of times each of them appear on the input string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T': 21, 'A': 20, 'G': 17, 'C': 12}\n"
     ]
    }
   ],
   "source": [
    "# Create an empty dictionary\n",
    "dic = {}\n",
    "# Now as we loop through the input string we need to check if an entry in the dictionary already\n",
    "# exists. If it does, we simply increase its value by one, otherwise we create it.\n",
    "for nuc in sample:\n",
    "    if nuc in dic.keys():\n",
    "        dic[nuc] += 1\n",
    "    else:\n",
    "        dic[nuc] = 1\n",
    "# Print the dictionary. NOTE: dictionaries are inherently unordered!\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries are extremely useful, powerful, and elegant. So what is the complexity of this approach? This time we are creating a new data structure to store our frequencies. In this case we only have four different values, so the memory used is negligible but in general, if we had _d_ different values, we will need _O(d)_ space. Timewise, notice that using a dictionary we only have to loop through the input string once! So it only takes _O_(n) time. Can we make it more efficient? There is no way we can bring it down from _O_(n) but we can try to improve it by getting rid of the 'if', 'else' conditions inside the loop. There are two ways we can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'G': 17, 'A': 20, 'C': 12, 'T': 21}\n"
     ]
    }
   ],
   "source": [
    "# Manually initialize the dictionary keys:\n",
    "\n",
    "dic = {'A': 0, 'C': 0, 'T': 0, 'G': 0}\n",
    "for nuc in sample:\n",
    "    dic[nuc] += 1\n",
    "print (dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can afford to do this because we only have four different keys. It is easy to see how this approach would be terribly inefficient and tedious when dealing with a larger number of keys. In that case we can use a defaultdict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'T': 21, 'A': 20, 'G': 17, 'C': 12})\n"
     ]
    }
   ],
   "source": [
    "# Import defaultdict from the collections module\n",
    "from collections import defaultdict\n",
    "\n",
    "# We now initialize the defaultdict with an integer (whose default value is 0). What this does\n",
    "# is that if you try getting the value of a previously unseen key, it will give you the \n",
    "# default value of 0, freeing us from the need to manually initiate each key.\n",
    "dic = defaultdict(int)\n",
    "for nuc in sample:\n",
    "    dic[nuc] += 1\n",
    "print (dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time this different approaches. We will use the timeit module, so first we have to wrap the approaches in functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_print(s):\n",
    "    a, c, g, t = s.count(\"A\"), s.count(\"C\"), s.count(\"G\"), s.count(\"T\")\n",
    "    \n",
    "def simple_loop(s):\n",
    "    values = \"ACGT\"\n",
    "    counts = []\n",
    "    for nuc in values:\n",
    "        counts.append((nuc, s.count(nuc)))\n",
    "        \n",
    "def normal_dic(s):\n",
    "    dic = {}\n",
    "    for nuc in s:\n",
    "        if nuc in dic.keys():\n",
    "            dic[nuc] += 1\n",
    "        else:\n",
    "            dic[nuc] = 1\n",
    "\n",
    "def initialize_dic(s):\n",
    "    dic = {'A': 0, 'C': 0, 'T': 0, 'G': 0}\n",
    "    for nuc in s:\n",
    "        dic[nuc] += 1\n",
    "    \n",
    "def default_dic(s):\n",
    "    dic = defaultdict(int)\n",
    "    for nuc in s:\n",
    "        dic[nuc] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count statements: 0.189124755008379\n",
      "Count using a loop: 0.22352015800424851\n",
      "Uninitialized dict: 1.8125681559904478\n",
      "Manualy initialized dict: 0.7410088409960736\n",
      "Default dict: 0.9210935779847205\n"
     ]
    }
   ],
   "source": [
    "# We can now use the timeit module to time them\n",
    "import timeit\n",
    "n = 100000\n",
    "\n",
    "t = timeit.Timer(lambda: simple_print(sample))\n",
    "print(\"Count statements:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: simple_loop(sample))\n",
    "print(\"Count using a loop:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: normal_dic(sample))\n",
    "print(\"Uninitialized dict:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: initialize_dic(sample))\n",
    "print(\"Manualy initialized dict:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: default_dic(sample))\n",
    "print(\"Default dict:\", t.timeit(number=n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the above results confirm our intuition: when using dictionaries, it is clear that either initializing all the keys, or using a defaultdic gives us better performance than checking whether a particular entry exists at each step. But how come that looping through the string 4 times, as in the first two approaches takes so little time? The built-in count function in python is written and precisely optimized in C, a lower-level and generally much faster language than python. So even though simple intuition tells us that looping once should be quicker than looping four times should be quicker, the difference in performance between a python loop and a C loop can be huge. But we may wonder if this depends on factors such as the lenght of the array and the number of items we are counting. What would happen if our input array was a million times larger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count statements: 0.7458192369958851\n",
      "Count using a loop: 0.7867667690152302\n",
      "Uninitialized dict: 17.446918549016118\n",
      "Manualy initialized dict: 7.996425088989781\n",
      "Default dict: 7.910343224008102\n"
     ]
    }
   ],
   "source": [
    "sample_million = sample * 1000000\n",
    "n = 1\n",
    "\n",
    "t = timeit.Timer(lambda: simple_print(sample_million))\n",
    "print(\"Count statements:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: simple_loop(sample_million))\n",
    "print(\"Count using a loop:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: normal_dic(sample_million))\n",
    "print(\"Uninitialized dict:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: initialize_dic(sample_million))\n",
    "print(\"Manualy initialized dict:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: default_dic(sample_million))\n",
    "print(\"Default dict:\", t.timeit(number=n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple count statements are still faster, with ~10x better speed. Let's look at another practical application. A FASTQ file contains not only a nucleotide chain, but also a quality index associated for every entry in the chain. These quality indices can take the following values:\n",
    "\n",
    "    !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\n",
    "\n",
    "So what would happen if instead of counting nucleotides we wanted to count how many times a particular quality index occurs? Instead of looking at four possible values (\"ACTG\") we are now looking at 94! Let's look at how the different approaches compare (we will just look at counting using a loop, uninitialized dict, and default dict as those are the only ones that make sense in this scenario):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to redefine one of the functions:\n",
    "def simple_loop_mod(s):\n",
    "    values = \"\"\"!\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\"\"\"\n",
    "    counts = []\n",
    "    for nuc in values:\n",
    "        counts.append((nuc, s.count(nuc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count using a loop: 3.744830648007337\n",
      "Uninitialized dict: 16.30485448401305\n",
      "Default dict: 8.638961379008833\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "\n",
    "t = timeit.Timer(lambda: simple_loop_mod(sample_million))\n",
    "print(\"Count using a loop:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: normal_dic(sample_million))\n",
    "print(\"Uninitialized dict:\", t.timeit(number=n))\n",
    "\n",
    "t = timeit.Timer(lambda: default_dic(sample_million))\n",
    "print(\"Default dict:\", t.timeit(number=n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see that the performance of the dictionaries remains unchanged, but the performance of the simple count calls drops dramatically, going from a 10x improvement to a 2x.\n",
    "\n",
    "We can now calculate the nucleotide frequency in the actual input using the simplest and fastest method. First we need to load the txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 221 204 205\n"
     ]
    }
   ],
   "source": [
    "# Open txt file, read into memory, and close file\n",
    "f = open('rosalind_dna.txt', 'r')\n",
    "s = f.readline()\n",
    "\n",
    "print(s.count(\"A\"), s.count(\"C\"), s.count(\"G\"), s.count(\"T\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "In this short notebook we have seen the difference in performance between the built-in count method and more advanced but very common techniques such as dictionaries. The \"C\" backbone and precise optimization of the built-in python function make the simpler technique faster in than dictionaries in most cases. Caution is advised though, since this may not be the case for very large input strings and very large numbers of items to count (which translates into loops through the input)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
